hmLoadTopic({
hmKeywords:"AlphaCPU,Barrier,BIS,Box,Branch,branchTaken,branchTarget,Cache,CALL_PAL,canDualIssue,CBox,CodeGeneration,ContextSwitch,cpuId,Decode,DecodeCache,DecodedInstruction,deferWriteback,Dispatch,DualCache,EBox,EXCB,execute,ExecutionBox,Fault,faultPending,FBox,FetchResult,flags,FloatingPoint,Flyweight,functionCode,generate_all_grains,Grain,GrainAutoRegistrar,GrainFactoryLib,GrainMaster,GrainPlatform,GrainRegistrationCore,GrainResolver,GrainType,HW_LD,HW_MFPR,HW_MTPR,HW_REI,HW_ST,IBox,ILLEGAL_INSTRUCTION,InstructionGrain,InstructionGrainRegistry,Integer,Invalidation,latency,LazyDecode,LetterBox,lookup,m_cBox,m_eBox,m_fBox,m_mBox,m_palBox,makeGrainKey,MB,MBox,Memory,mnemonic,needsWriteback,opcode,PACache,PaKey,PAL,PalBox,payLoad,PCCache,PcKey,Pipeline,PipelineSlot,platform,Polymorphic,Python,rawBits,REGISTER_GRAIN,Registry,resolveGrain,Routing,Seqlock,Sharded,SharedGlobal,Singleton,Slot,stalled,throughput,trapCode,TSV,Uniform,Virtual,Vtable,Wildcard,WMB",
hmTitle:"Appendix G – Instruction Grain Mechanics",
hmDescription:"This appendix provides the authoritative reference for the instruction grain subsystem — the mechanism by which Alpha AXP instructions are represented, resolved, cached, and...",
hmPrevLink:"appendixf-spam(ptetranslationbuffer).html",
hmNextLink:"g_1-decodedinstructionquickreference.html",
hmParentLink:"appendix---trait-examples.html",
hmBreadCrumbs:"<a href=\"license-_-attributions.html\">ASA-EMulatR Reference Guide<\/a> &gt; <a href=\"index.html\">Introduction<\/a> &gt; <a href=\"appendix---trait-examples.html\">Appendix<\/a>",
hmTitlePath:"ASA-EMulatR Reference Guide > Introduction > Appendix > Appendix G - Instruction Grain Mechanics",
hmHeader:"<h1 class=\"p_Heading1\" style=\"page-break-after: avoid;\"><span class=\"f_Heading1\">Appendix G – Instruction Grain Mechanics<\/span><\/h1>\n\r",
hmBody:"<p class=\"p_Normal\">This appendix provides the authoritative reference for the instruction grain subsystem — the mechanism by which Alpha AXP instructions are represented, resolved, cached, and executed. The grain is the central abstraction in ASA-EMulatR: it mediates every instruction execution from decode through retirement. Understanding the grain lifecycle is prerequisite to understanding any chapter that discusses instruction execution.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.1 What Is an Instruction Grain<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">An instruction grain is a lightweight, immutable, pre-registered C++ object that encapsulates the identity and execution behavior of a single Alpha AXP instruction type. One grain exists for each unique combination of opcode, function code, and platform — approximately 616 grains cover the entire Alpha AXP instruction set including platform-specific variants for VMS, Tru64\/Unix, and PAL-internal operations.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Flyweight pattern:<\/strong> Grains are not allocated per-instruction. They are singletons — one shared object per instruction type, pre-registered at program startup. Every ADDQ instruction executed during the lifetime of the emulator uses the same ADDQ grain object. The grain carries no per-instance state; all per-instruction data (operands, results, faults) lives in the PipelineSlot. This is the GoF flyweight pattern: shared intrinsic state (the grain) with extrinsic state passed in via the slot.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">What a grain knows:<\/strong> its opcode, its function code, its mnemonic, its instruction format (operate, memory, branch, PAL), its grain type classification, its target platform, and how to execute itself given a PipelineSlot. What a grain does not know: the current PC, the register values, the memory address, the fault state. All of those belong to the slot.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.2 InstructionGrain Base Class<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Every grain inherits from InstructionGrain, which defines the polymorphic interface:<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">struct&nbsp;InstructionGrain&nbsp;{<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;\/\/&nbsp;──&nbsp;Data&nbsp;Members&nbsp;(8&nbsp;bytes)&nbsp;────────────────────────────<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;quint32&nbsp;rawBits;&nbsp;\/\/&nbsp;Original&nbsp;32-bit&nbsp;instruction&nbsp;(template&nbsp;default)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;quint8&nbsp;flags;&nbsp;\/\/&nbsp;Packed&nbsp;format\/issue&nbsp;flags&nbsp;(GrainFlags)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;quint8&nbsp;latency;&nbsp;\/\/&nbsp;Expected&nbsp;cycle&nbsp;latency<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;quint8&nbsp;throughput;&nbsp;\/\/&nbsp;Instructions&nbsp;per&nbsp;cycle&nbsp;(reciprocal)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;\/\/&nbsp;──&nbsp;Vtable&nbsp;pointer&nbsp;(8&nbsp;bytes)&nbsp;──────────────────────────<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;\/\/&nbsp;Total:&nbsp;16&nbsp;bytes&nbsp;per&nbsp;grain<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;virtual&nbsp;~InstructionGrain()&nbsp;=&nbsp;0;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;\/\/&nbsp;──&nbsp;Virtual&nbsp;Interface&nbsp;───────────────────────────────<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;virtual&nbsp;quint8&nbsp;opcode()&nbsp;const&nbsp;=&nbsp;0;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;virtual&nbsp;quint16&nbsp;functionCode()&nbsp;const&nbsp;=&nbsp;0;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;virtual&nbsp;QString&nbsp;mnemonic()&nbsp;const&nbsp;=&nbsp;0;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;virtual&nbsp;GrainType&nbsp;grainType()&nbsp;const&nbsp;=&nbsp;0;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;virtual&nbsp;void&nbsp;execute(PipelineSlot&amp;&nbsp;slot)&nbsp;const&nbsp;noexcept&nbsp;=&nbsp;0;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;virtual&nbsp;GrainPlatform&nbsp;platform()&nbsp;const&nbsp;{<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;return&nbsp;GrainPlatform::NONE;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;}<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;AXP_ALWAYS_INLINE&nbsp;bool&nbsp;canDualIssue()&nbsp;const&nbsp;noexcept&nbsp;{<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;return&nbsp;(flags&nbsp;&amp;&nbsp;GF_CanDualIssue)&nbsp;!=&nbsp;0;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;}<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">};<\/span><\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Memory footprint:<\/strong> 8 bytes of data + 8 bytes of vtable pointer = 16 bytes per grain. With 616 grains, the entire grain registry occupies approximately 10 KB. This fits comfortably in L1 cache.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">The execute() contract:<\/strong> <span class=\"f_CodeExample\">execute(PipelineSlot&amp; slot)<\/span> is the sole entry point for instruction execution. Every grain overrides this method. It takes a PipelineSlot by reference, performs all work through box delegation, and returns void. All results, faults, and stall conditions are communicated by modifying the slot in place — never by return value. This is the &quot;letter box&quot; pattern: the slot is both the input envelope and the output mailbox.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">The rawBits field:<\/strong> rawBits on the grain is a template default, not the current instruction\'s bits. The actual instruction bits for the executing instruction are in <span class=\"f_CodeExample\">slot.di.rawBits()<\/span>. The grain is a shared singleton — it cannot carry per-instruction data.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.3 Grain Registration<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.3.1 The Single Source of Truth: GrainMaster.tsv<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The authoritative definition of all Alpha AXP instructions is a tab-separated table (GrainMaster.tsv) containing one row per instruction type. Each row specifies: mnemonic\/qualifier, opcode (hex and decimal), function code, instruction format, architecture (VMS, Unix, PAL, Alpha), and classification metadata.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">This table is the single source of truth. All grain header files, registration code, and validation are generated from this table. Corrections to instruction encodings are made in the table and regenerated — never by manually editing individual grain headers.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.3.2 Code Generation: generate_all_grains.py<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">A Python code generator (python\/generate_all_grains.py) reads GrainMaster.tsv and produces:<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Per-grain inline headers<\/strong> — one header per instruction type, organized by category (grains\/generated\/PAL\/, grains\/generated\/Integer\/, grains\/generated\/FloatingPoint\/, grains\/generated\/Memory\/, grains\/generated\/Branch\/). Each header defines a class inheriting from InstructionGrain, implementing all virtual methods, and including the REGISTER_GRAIN macro.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">A master include file<\/strong> — a single header that includes all generated grain headers, ensuring every grain is compiled and registered.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The generator validates the input table during generation: detecting opcode\/function code collisions, flagging architecture conflicts (VMS vs Unix overlapping encodings), verifying function code ranges, and ensuring no duplicate definitions. Generation fails on validation errors.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.3.3 Compile-Time Registration<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Each generated grain header includes the REGISTER_GRAIN macro (from GrainRegistrationCore.h):<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">#define&nbsp;REGISTER_GRAIN(GrainType)&nbsp;\\<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;static&nbsp;GrainAutoRegistrar&lt;GrainType&gt;&nbsp;\\<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;GRAIN_CONCAT(autoReg_,&nbsp;__COUNTER__)<\/span><\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">GrainAutoRegistrar is a template struct whose constructor creates a static instance of the grain class and registers it with the InstructionGrainRegistry singleton:<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">template&lt;typename&nbsp;GrainType&gt;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">struct&nbsp;GrainAutoRegistrar&nbsp;{<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;GrainAutoRegistrar()&nbsp;{<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;static&nbsp;GrainType&nbsp;grain;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;InstructionGrainRegistry::instance().registerGrain(<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;grain.opcode(),&nbsp;grain.functionCode(),&nbsp;&amp;grain);<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;}<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">};<\/span><\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Registration occurs during static initialization, before main() executes. By the time AlphaCPU initializes, all 616 grains are registered and ready for lookup. No runtime allocation occurs — every grain is a static object with program lifetime.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.4 Grain Resolution<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.4.1 InstructionGrainRegistry<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">InstructionGrainRegistry is a global singleton that stores all registered grains in a flat hash map keyed by <span class=\"f_CodeExample\">makeGrainKey(opcode, functionCode)<\/span>. The key combines the 6-bit opcode and the function code into a single lookup value. The registry supports platform-aware lookup: it first attempts an exact match with the specified GrainPlatform, then falls back to GrainPlatform::NONE (architecture-universal grains) if no platform-specific match exists.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.4.2 GrainResolver<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">GrainResolver is the runtime entry point for grain lookup. IBox calls <span class=\"f_CodeExample\">GrainResolver::instance().resolve(pc, opcode, func)<\/span> when decoding an instruction. The resolver delegates to the registry\'s <span class=\"f_CodeExample\">lookup(opcode, func, platform)<\/span> method. If lookup returns nullptr, the instruction is unimplemented — IBox records it as nullptr in the DecodedInstruction and the pipeline will fault with ILLEGAL_INSTRUCTION when the empty grain reaches stage_EX().<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The resolver holds a configurable platform setting (<span class=\"f_CodeExample\">m_overridePlatform<\/span>) defaulting to GrainPlatform::VMS. This allows the same binary to emulate different PAL operating system personalities by switching the platform before boot.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.4.3 PAL Hardware Opcode Wildcard<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Five opcodes are PAL-mode hardware instructions whose &quot;function code&quot; field carries a variable operand (typically an IPR index) rather than a fixed encoding: HW_MFPR (0x19), HW_LD (0x1B), HW_MTPR (0x1D), HW_REI (0x1E), HW_ST (0x1F). For these opcodes, the registry cannot match on function code because the function code varies per instruction instance (e.g., HW_MTPR to SIRR uses function code 0x0018, HW_MTPR to ASTRR uses 0x0019).<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The resolution strategy: on exact-match miss, if the opcode is one of the five PAL hardware opcodes, the resolver falls back to <span class=\"f_CodeExample\">lookup(opcode, 0x0000)<\/span> — the wildcard registration. Each PAL hardware grain is registered with function code 0x0000, and the actual IPR index or operand is extracted from <span class=\"f_CodeExample\">slot.di.rawBits()<\/span> at execution time by the grain\'s execute() method. This avoids registering thousands of per-IPR grains for a handful of PAL opcodes.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.5 Decode Cache Integration<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.5.1 Dual Cache Architecture<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">IBox accesses two independent decode caches through global singleton accessors (<span class=\"f_CodeExample\">pcDecodeCache()<\/span> and <span class=\"f_CodeExample\">paDecodeCache()<\/span>). Both caches store DecodedInstruction records — not grain pointers alone. A DecodedInstruction contains the grain pointer, decoded register indices (ra, rb, rc), literal value, branch displacement, instruction semantics, PC, and physical address. This means decode happens once; all subsequent encounters of the same instruction skip the entire decode and grain resolution path.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The two caches serve fundamentally different roles and have different sharing semantics:<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">PA Cache (Physical Address) — Global, Shared Across All CPUs<\/strong><\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Keyed by physical address (PaKey::fromPA(pa)). The PA cache is a single global instance shared by all CPUs. A decoded instruction at physical address 0x5000 is identical regardless of which CPU decodes it — the same physical memory contains the same instruction bits, resolving to the same grain, with the same decoded register fields. When CPU 0 decodes an instruction and inserts it into the PA cache, CPU 1 encountering the same physical address gets an immediate hit and skips the entire decode path. This is the &quot;decode once, shared everywhere&quot; principle.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The PA cache survives context switches because physical addresses are identity-stable — a context switch changes virtual-to-physical mappings but does not change the code at a physical address. The PA cache is invalidated only on self-modifying code (a store to a physical address that has a cached decode) and page unmap (the physical page is recycled for different content).<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">PC Cache (Virtual Address) — Global Singleton, Internally Sharded by CPU<\/strong><\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Keyed by virtual PC (PcKey::fromVA(pc)). The PC cache is a single global singleton but is internally sharded by CPU ID. Each CPU has its own partition within the PC cache because virtual-to-physical mappings are per-process — two CPUs running different processes may map the same virtual address to different physical pages. CPU 0\'s PC=0x10000 may decode to ADDQ while CPU 1\'s PC=0x10000 (in a different process) may decode to SUBQ.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The PC cache is the fast-path cache. On sequential code execution within a single process, the PC cache provides a direct hit on the next instruction. The PC cache is invalidated per-CPU on context switch (VA mappings change for that CPU), TBIA (TLB invalidate all), and ITBIS (instruction TLB invalidate single). Invalidation uses an O(1) generation counter bump — no entry walking is required.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Cache hierarchy summary:<\/strong><\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<div style=\"text-align: left; text-indent: 0; padding: 0 0 0 0; margin: 0 0 0 0;\"><table style=\"border:none; border-spacing:0; border-collapse:collapse;\">\n\r<thead>\n\r<tr>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Cache<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Key<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Scope<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Structure<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Survives Context Switch<\/strong><\/p>\n\r<\/th>\n\r<\/tr>\n\r<\/thead>\n\r<tbody>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">PC Cache<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Virtual PC &gt;&gt; 2<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Per-CPU (sharded)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">4-way set-associative, 4096 buckets<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">No — flushed per-CPU<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">PA Cache<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Physical Address &gt;&gt; 2<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Global (shared, all CPUs)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Direct-mapped or set-associative<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Yes — physical identity unchanged<\/p>\n\r<\/td>\n\r<\/tr>\n\r<\/tbody>\n\r<\/table>\n\r<\/div>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Memory footprint:<\/strong> The PA cache is a single shared instance — its memory cost is fixed regardless of CPU count. The PC cache is sharded by CPU, so its memory scales with CPU count. In a 4-CPU configuration: one shared PA cache (~64–128 KB) plus four PC cache shards (4 × ~2 MB = ~8 MB). Total decode cache memory: approximately 8–9 MB for a 4-CPU system. Compare to the naive approach of duplicating both caches per CPU (4 × ~4 MB = ~16 MB with no cross-CPU decode sharing).<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Concurrency:<\/strong> Both caches use lock-free reads via seqlock\/versioning. The PA cache (shared across CPUs) requires atomic operations for concurrent inserts from multiple CPUs — a seqlock on each bucket ensures torn reads are detected and retried. The PC cache shards are per-CPU with no cross-CPU contention on reads or writes within a shard.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.5.2 The Lazy Decode-Once Pattern<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The instruction fetch and decode flow follows a lazy decode-once pattern — the grain is resolved and the instruction is decoded only on the first encounter. All subsequent encounters use the cached DecodedInstruction:<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">IBox::fetchAndDecode(pc,&nbsp;pa,&nbsp;cpuId):<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;┌─&nbsp;STEP&nbsp;1:&nbsp;PC&nbsp;Cache&nbsp;Lookup&nbsp;(fastest&nbsp;path,&nbsp;per-CPU)&nbsp;────────────┐<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;PcKey&nbsp;pcKey&nbsp;=&nbsp;PcKey::fromVA(pc)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;cached&nbsp;=&nbsp;pcDecodeCache().lookup(cpuId,&nbsp;pcKey)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;if&nbsp;(cached&nbsp;&amp;&amp;&nbsp;cached→physicalAddress&nbsp;==&nbsp;pa)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;return&nbsp;cached&nbsp;←&nbsp;HIT&nbsp;(~4–7&nbsp;cycles)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;└──────────────────────────────────────────────────────────────┘<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;miss<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;┌─&nbsp;STEP&nbsp;2:&nbsp;PA&nbsp;Cache&nbsp;Lookup&nbsp;(shared,&nbsp;all&nbsp;CPUs)&nbsp;─────────────────┐<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;PaKey&nbsp;paKey&nbsp;=&nbsp;PaKey::fromPA(pa)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;cached&nbsp;=&nbsp;paDecodeCache().lookup(paKey)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;if&nbsp;(cached)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;pcDecodeCache().insert(cpuId,&nbsp;pcKey,&nbsp;*cached)&nbsp;←&nbsp;promote&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;return&nbsp;cached&nbsp;←&nbsp;HIT&nbsp;(~10–20&nbsp;cycles)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;(another&nbsp;CPU&nbsp;already&nbsp;decoded&nbsp;this&nbsp;instruction)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;└──────────────────────────────────────────────────────────────┘<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;miss<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;┌─&nbsp;STEP&nbsp;3:&nbsp;Full&nbsp;Decode&nbsp;(cold&nbsp;path)&nbsp;────────────────────────────┐<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;rawBits&nbsp;=&nbsp;m_guestMemory→readInst32(pa) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;opcode&nbsp;=&nbsp;extractOpcode(rawBits)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;func&nbsp;=&nbsp;extractFunction(rawBits)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;grain&nbsp;=&nbsp;GrainResolver::resolve(pc,&nbsp;opcode,&nbsp;func)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;di&nbsp;=&nbsp;buildDecodedInstruction(grain,&nbsp;rawBits,&nbsp;pc,&nbsp;pa)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;paDecodeCache().insert(paKey,&nbsp;di)&nbsp;←&nbsp;shared&nbsp;globally&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;pcDecodeCache().insert(cpuId,&nbsp;pcKey,&nbsp;di)&nbsp;←&nbsp;per-CPU&nbsp;shard&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;│&nbsp;return&nbsp;di&nbsp;←&nbsp;MISS&nbsp;(~135–370&nbsp;cycles)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;│<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;└──────────────────────────────────────────────────────────────┘<\/span><\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">For hot loops, the PC cache hit rate approaches 100% — the entire decode and resolution cost is amortized to zero. For cold code (first execution, post-flush, post-context-switch), the full decode path runs once and populates both caches. In SMP configurations, the PA cache provides cross-CPU sharing: when CPU 0 decodes a shared library function, CPUs 1–3 hitting the same physical address get an immediate PA cache hit without repeating the decode.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.5.3 Cache Invalidation Events<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<div style=\"text-align: left; text-indent: 0; padding: 0 0 0 0; margin: 0 0 0 0;\"><table style=\"border:none; border-spacing:0; border-collapse:collapse;\">\n\r<thead>\n\r<tr>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Event<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">PC Cache<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">PA Cache<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Scope<\/strong><\/p>\n\r<\/th>\n\r<\/tr>\n\r<\/thead>\n\r<tbody>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Context switch<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Flush (generation bump)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Untouched<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Single CPU (the switching CPU)<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">TBIA (invalidate all TLB)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Flush (generation bump)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Untouched<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Single CPU<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">ITBIS (invalidate single VA)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Invalidate entry<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Untouched<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Single CPU<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Self-modifying code (store to code PA)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Flush (conservative)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Invalidate PA entry<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">All CPUs<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Page unmap (PFN recycled)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Untouched<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Invalidate page range<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">All CPUs (shared PA cache)<\/p>\n\r<\/td>\n\r<\/tr>\n\r<\/tbody>\n\r<\/table>\n\r<\/div>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The key principle: PC cache invalidations are virtual events (the VA→PA mapping changed, not the code). PA cache invalidations are physical events (the code itself changed or the physical page was recycled). This separation is what allows the PA cache to be shared globally and survive context switches — physical identity is stable across processes and CPUs.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Self-modifying code note:<\/strong> On self-modifying code detection (a store to a physical address with a cached decode), the PA cache entry is invalidated globally (all CPUs see the invalidation because it is a single shared instance). The PC cache is flushed conservatively for all CPUs because any CPU may hold a PC cache entry pointing to the now-stale physical decode. This is the most expensive invalidation event but is extremely rare in practice — Alpha AXP code is not self-modifying outside of PAL loader operations.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.6 The Uniform Execution Contract<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Every instruction grain follows the same execution contract without exception. There is no special-case logic for any instruction category. The contract:<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">1. The pipeline calls grain→execute(slot).<\/strong> This is the only entry point. The pipeline does not inspect the grain type, does not branch on instruction category, and does not call any box directly. The grain is the sole dispatcher.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">2. The grain calls box→executeXXX(slot).<\/strong> The grain knows which box handles its instruction class: EBox for integer operations, FBox for floating-point, MBox for memory access, PalBox for PAL functions. The grain calls the specific box method for its instruction (e.g., <span class=\"f_CodeExample\">slot.m_eBox→executeAdd(slot)<\/span>). The grain does not perform the computation itself — it delegates to the box.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">3. The box performs all work and modifies the slot.<\/strong> The box reads operands from the register file via the slot, performs the computation, and writes results back into the slot: slot.payLoad for the result value, slot.needsWriteback = true if a register write is pending, slot.faultPending = true with slot.trapCode if a fault was detected, slot.stalled = true if the operation cannot complete this cycle.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">4. The grain returns.<\/strong> No return value. The pipeline inspects the slot after execute() returns and takes action based on the slot\'s state: advance to MEM (normal), stall (slot.stalled), prepare fault delivery (slot.faultPending), or flush younger stages (slot.flushPipeline for branch misprediction).<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">No grain ever modifies architectural state directly.<\/strong> No grain writes to the register file. No grain writes to memory. No grain updates the PC. All side effects flow through the slot and are committed by the pipeline at the appropriate stage (commitPending in MEM, store commit in WB, PC update at retirement). This invariant is what makes the pipeline restartable — a faulting or flushed instruction\'s grain execution has no observable side effect.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.7 Execution Bias: There Is None<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The grain execution model has no execution bias. Every grain — integer arithmetic, floating-point, memory load, memory store, branch, barrier, CALL_PAL — follows the identical four-step contract described in Section G.6. The pipeline does not prioritize, reorder, or treat any grain category differently from any other.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Specifically:<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">No opcode-based dispatch in the pipeline.<\/strong> The pipeline never inspects slot.di.opcode to decide what to do. It calls grain→execute(slot) unconditionally. The grain\'s virtual dispatch (vtable call) is the sole routing mechanism.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">No fast-path \/ slow-path distinction.<\/strong> Integer operations do not get a cheaper execution path than floating-point operations at the pipeline level. Latency differences are modeled within the box (FBox may set slot.stalled for multi-cycle FP), not by the pipeline treating the grain differently.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">No instruction-specific pipeline logic.<\/strong> The only instruction-specific behavior in the pipeline is in stage_WB(), where <span class=\"f_CodeExample\">isCallPal(slot.di)<\/span> is checked for the CALL_PAL serialization path. This is a retirement concern (Section K.6), not an execution concern — the grain itself executed through the standard path in stage_EX() like any other instruction.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Why this matters:<\/strong> Bias-free execution guarantees that adding a new instruction type requires only a new grain class and registration — zero pipeline modifications. The pipeline is closed to modification, open to extension. This is the primary maintainability benefit of the grain architecture.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.8 Box Routing<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Each grain routes to exactly one execution box. The routing is determined at compile time by the grain\'s execute() implementation — there is no runtime dispatch table.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<div style=\"text-align: left; text-indent: 0; padding: 0 0 0 0; margin: 0 0 0 0;\"><table style=\"border:none; border-spacing:0; border-collapse:collapse;\">\n\r<thead>\n\r<tr>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Box<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Grain Types<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Examples<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Access Pattern<\/strong><\/p>\n\r<\/th>\n\r<\/tr>\n\r<\/thead>\n\r<tbody>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">EBox<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Integer arithmetic, logical, shift, compare, conditional move<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">ADDQ, SUBQ, AND, BIS, SRL, CMPEQ, CMOVNE<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">slot.m_eBox→executeXXX(slot)<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">FBox<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Floating-point arithmetic, conversion, comparison<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">ADDT, MULT, DIVT, CVTQS, CMPTEQ, SQRTS<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">slot.m_fBox→executeXXX(slot, variant)<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">MBox<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Memory load, store, unaligned access, LDA\/LDAH<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">LDQ, STQ, LDQ_U, STQ_U, LDA, LDAH, LDL, STL<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">slot.m_mBox→executeXXX(slot)<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">CBox<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Memory barriers, cache hints<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">MB, WMB, EXCB, TRAPB, FETCH, FETCH_M, ECB<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">slot.m_cBox→executeXXX(slot)<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">PalBox<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">PAL functions<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">CALL_PAL (HALT, CSERVE, SWPCTX, etc.)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">slot.m_palBox→executeCallPal(slot)<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">IBox<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Branch resolution (condition evaluation only)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">BEQ, BNE, BGT, BR, BSR, JMP, JSR, RET<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Grain evaluates condition directly from slot register values<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">(None)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">NOP-like instructions<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">UNOP, FNOP, WH64<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Grain returns immediately (no box call)<\/p>\n\r<\/td>\n\r<\/tr>\n\r<\/tbody>\n\r<\/table>\n\r<\/div>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">FP variant routing:<\/strong> Floating-point grains decode the instruction variant (\/S, \/SU, \/SUC, \/SUI, \/D, \/C, etc.) from the function code before calling the box. The variant is passed as a parameter to the FBox method: <span class=\"f_CodeExample\">slot.m_fBox→executeAdd(slot, variant)<\/span>. The FBox uses the variant to select rounding mode, trap handling, and IEEE compliance behavior.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Box access:<\/strong> Boxes are owned by AlphaCPU and pointers are published directly to the PipelineSlot. The slot holds direct box pointers: slot.m_eBox, slot.m_fBox, slot.m_mBox, slot.m_cBox, slot.m_palBox. The call chain <span class=\"f_CodeExample\">slot.m_eBox→executeAdd(slot)<\/span> resolves to a single pointer dereference — no intermediate accessor, no APC indirection. This is a hot path (called for every instruction execution) and is always in L1 cache.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.9 Grain Categories<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The 616 grains are organized into categories that correspond to the Alpha AXP instruction set architecture. Categories determine the generated header directory and the GrainType classification:<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<div style=\"text-align: left; text-indent: 0; padding: 0 0 0 0; margin: 0 0 0 0;\"><table style=\"border:none; border-spacing:0; border-collapse:collapse;\">\n\r<thead>\n\r<tr>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Category<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Directory<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Approx. Count<\/strong><\/p>\n\r<\/th>\n\r<th style=\"vertical-align:top; background-color:#00FFFF; padding:0; border:solid thin #000000;\" scope=\"col\"><p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Opcode Range<\/strong><\/p>\n\r<\/th>\n\r<\/tr>\n\r<\/thead>\n\r<tbody>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Integer Operate<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">grains\/generated\/Integer\/<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">~120<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">0x10–0x13<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Floating-Point Operate<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">grains\/generated\/FloatingPoint\/<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">~250<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">0x14–0x17<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Memory Access<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">grains\/generated\/Memory\/<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">~50<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">0x08–0x0F, 0x20–0x2F<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Branch<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">grains\/generated\/Branch\/<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">~20<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">0x30–0x3F, 0x1A<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">PAL (CALL_PAL functions)<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">grains\/generated\/PAL\/<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">~60<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">0x00<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">PAL Hardware<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">grains\/generated\/PAL\/<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">~5<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">0x19, 0x1B, 0x1D, 0x1E, 0x1F<\/p>\n\r<\/td>\n\r<\/tr>\n\r<tr>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">Miscellaneous \/ Barrier<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">grains\/generated\/Misc\/<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">~15<\/p>\n\r<\/td>\n\r<td style=\"vertical-align:top; padding:0; border:solid thin #000000;\"><p class=\"p_Normal\">0x18 (MISC function codes)<\/p>\n\r<\/td>\n\r<\/tr>\n\r<\/tbody>\n\r<\/table>\n\r<\/div>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">Floating-point grains account for approximately 40% of the total count because each FP mnemonic (ADDT, SUBT, etc.) is expanded into multiple variants representing different IEEE rounding and trap modes (\/S, \/SU, \/SUC, \/SUI, \/D, \/C, etc.). Each variant has a unique function code and a dedicated grain.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.10 Grain Lifecycle Summary<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\">The complete lifecycle of a grain from creation to consumption:<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">BUILD&nbsp;TIME:<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;generate_all_grains.py&nbsp;reads&nbsp;GrainMaster.tsv<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;produces&nbsp;~616&nbsp;inline&nbsp;header&nbsp;files<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;produces&nbsp;master&nbsp;include&nbsp;file<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">COMPILE&nbsp;TIME:<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;REGISTER_GRAIN&nbsp;macro&nbsp;creates&nbsp;static&nbsp;GrainAutoRegistrar&nbsp;objects<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;each&nbsp;registrar&nbsp;creates&nbsp;a&nbsp;static&nbsp;grain&nbsp;instance&nbsp;(program&nbsp;lifetime)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;each&nbsp;registrar&nbsp;calls&nbsp;InstructionGrainRegistry::registerGrain()<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;616&nbsp;grains&nbsp;registered&nbsp;before&nbsp;main()&nbsp;executes<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">RUNTIME&nbsp;—&nbsp;First&nbsp;encounter&nbsp;of&nbsp;an&nbsp;instruction:<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;IBox::fetchAndDecode(pc,&nbsp;pa)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;PC&nbsp;cache&nbsp;miss&nbsp;→&nbsp;PA&nbsp;cache&nbsp;miss<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;readInst32(pa)&nbsp;fetches&nbsp;raw&nbsp;bits&nbsp;from&nbsp;memory<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;GrainResolver::resolve(pc,&nbsp;opcode,&nbsp;func)&nbsp;→&nbsp;grain&nbsp;pointer<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;buildDecodedInstruction(grain,&nbsp;raw,&nbsp;pc,&nbsp;pa)&nbsp;→&nbsp;full&nbsp;decode<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;insert&nbsp;into&nbsp;PA&nbsp;cache&nbsp;and&nbsp;PC&nbsp;cache<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;return&nbsp;DecodedInstruction&nbsp;to&nbsp;pipeline&nbsp;via&nbsp;FetchResult<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">RUNTIME&nbsp;—&nbsp;Subsequent&nbsp;encounters:<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;IBox::fetchAndDecode(pc,&nbsp;pa)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;PC&nbsp;cache&nbsp;hit&nbsp;→&nbsp;return&nbsp;cached&nbsp;DecodedInstruction<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;(grain&nbsp;resolution&nbsp;and&nbsp;decode&nbsp;cost&nbsp;=&nbsp;zero)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">RUNTIME&nbsp;—&nbsp;Execution:<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;stage_EX()&nbsp;→&nbsp;slot.grain→execute(slot)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;grain&nbsp;calls&nbsp;box→executeXXX(slot)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;box&nbsp;reads&nbsp;operands,&nbsp;computes,&nbsp;writes&nbsp;slot.payLoad<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;grain&nbsp;returns&nbsp;→&nbsp;pipeline&nbsp;inspects&nbsp;slot&nbsp;state<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">RUNTIME&nbsp;—&nbsp;Retirement:<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;stage_WB()&nbsp;→&nbsp;commitPending()&nbsp;writes&nbsp;register&nbsp;result<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;store&nbsp;commit&nbsp;writes&nbsp;SafeMemory&nbsp;(if&nbsp;store)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;predictor&nbsp;trained&nbsp;(if&nbsp;branch)<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;→&nbsp;instruction&nbsp;retired<\/span><\/p>\n\r<p class=\"p_CodeExample\"><span class=\"f_CodeExample\">&nbsp;(grain&nbsp;object&nbsp;is&nbsp;untouched&nbsp;—&nbsp;it&nbsp;is&nbsp;stateless,&nbsp;reusable&nbsp;forever)<\/span><\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<hr style=\"height:1px; color:#000000; border-width:0; background-color:#000000;\" \/><p class=\"p_Normal\">&nbsp;<\/p>\n\r<h2 class=\"p_Heading2\" style=\"page-break-after: avoid;\"><span class=\"f_Heading2\">G.11 Design Rationale<\/span><\/h2>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Why flyweight singletons instead of per-instruction objects?<\/strong> The Alpha AXP has 616 instruction types but executes billions of instructions per boot. Allocating an object per executed instruction would generate enormous allocation pressure. Flyweight singletons reduce the grain subsystem\'s memory footprint to ~10 KB regardless of execution volume.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Why virtual dispatch instead of function pointers or switch statements?<\/strong> Virtual dispatch via the vtable provides O(1) polymorphic execution with type safety. A switch statement on opcode would require the pipeline to know about instruction types — violating the bias-free execution principle. Function pointers would work but lack the encapsulation and type safety of the class hierarchy. Virtual dispatch also enables derived grain classes (e.g., template-based FP grains) to share implementation across variants.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Why code generation from a table instead of hand-written grains?<\/strong> With 616 instruction types, manual maintenance is unsustainable. Encoding errors (wrong opcode, wrong function code, missing registration) are the most common source of grain bugs. The table-driven approach ensures that corrections propagate uniformly and instantly. Validation is automated as part of generation.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Why dual decode caches instead of a single cache?<\/strong> Virtual addresses change on context switch; physical addresses do not. A single VA-keyed cache would require full invalidation on every context switch, flushing hot decode state for code that hasn\'t changed. The dual cache allows the PA cache to survive context switches while the PC cache is rebuilt from PA cache promotions — reducing cold-start cost after a switch.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_Normal\"><strong style=\"font-weight: bold;\">Why no execution bias?<\/strong> Bias-free execution means the pipeline is a fixed machine that processes any instruction identically. New instructions require only a new grain and registration — no pipeline code changes. This is critical for a 616-instruction ISA where instruction-specific pipeline logic would create an unmaintainable web of special cases.<\/p>\n\r<p class=\"p_Normal\">&nbsp;<\/p>\n\r<p class=\"p_SeeAlso\" style=\"page-break-after: avoid;\"><span class=\"f_SeeAlso\">See Also: <a href=\"alphapipeline-implementation.html\" class=\"topiclink\">Chapter 13 – AlphaPipeline Implementation<\/a> (stage_EX grain execution); <a href=\"chapter-14---execution-domains.html\" class=\"topiclink\">Chapter 14 – Execution Domains (“Boxes”)<\/a> (box routing); <a href=\"appendix-k----pipeline-retirem.html\" class=\"topiclink\">B.2 - Pipeline Retirement Mechanics<\/a> (deferred writeback, store commit); <a href=\"b_1---pipeline-cycle-mechanics.html\" class=\"topiclink\">B.1 - Pipeline Cycle Mechanics<\/a> (stage_EX in context); grainFactoryLib\/InstructionGrain.h; grainFactoryLib\/InstructionGrainRegistry.h; grainFactoryLib\/GrainResolver.h; grainFactoryLib\/ <a href=\"g_3-grainmaster_tsv.html\" class=\"topiclink\">GrainMaster.tsv<\/a>.<\/span><\/p>\n\r"
})
